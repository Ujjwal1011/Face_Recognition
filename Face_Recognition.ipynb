{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Photo Organiser"
      ],
      "metadata": {
        "id": "ovZJOaaj4jRA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This file is made as a server to run without any interuption and found all the faces from the folder and make a group of them\n"
      ],
      "metadata": {
        "id": "5qTLZLfa4QHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# With pip:\n",
        "!pip install facenet-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-tr3lyL476d0",
        "outputId": "56a25135-0b4a-4faa-9873-fb20b1264bbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: facenet-pytorch in /usr/local/lib/python3.10/dist-packages (2.6.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (1.26.4)\n",
            "Requirement already satisfied: Pillow<10.3.0,>=10.2.0 in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (10.2.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (2.32.3)\n",
            "Requirement already satisfied: torch<2.3.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (2.2.2)\n",
            "Requirement already satisfied: torchvision<0.18.0,>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (0.17.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (4.66.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3.0,>=2.2.0->facenet-pytorch) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "from torchvision.transforms import ToPILImage\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Initialize the MTCNN module\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "mtcnn = MTCNN(image_size=160, margin=0, min_face_size=20, thresholds=[0.5, 0.6, 0.6], factor=0.709, device=device)\n",
        "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)"
      ],
      "metadata": {
        "id": "Ja34U8lS4uAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zut3APzg4KI1"
      },
      "outputs": [],
      "source": [
        "def save_filenames_to_txt(folder_path, output_file):\n",
        "    with open(output_file, 'w') as f:\n",
        "        for root, _, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                f.write(file_path + '\\n')\n",
        "    print(f\"All filenames saved to {output_file}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(image_path):\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    img_cropped_list, probs = mtcnn(img, return_prob=True)\n",
        "\n",
        "    embeddings = []\n",
        "    face_images = []\n",
        "\n",
        "    if img_cropped_list is not None:\n",
        "        if isinstance(probs, float):\n",
        "            probs = [probs]\n",
        "\n",
        "        for img_cropped, prob in zip(img_cropped_list, probs):\n",
        "            if prob > 0.9:\n",
        "                if img_cropped.ndimension() == 2:  # Handle 2D tensor case\n",
        "                    img_cropped = img_cropped.unsqueeze(0).repeat(3, 1, 1)\n",
        "\n",
        "                if img_cropped.ndimension() == 3 and img_cropped.shape[0] == 3:  # [C, H, W]\n",
        "                    img_cropped_np = (\n",
        "                        img_cropped.permute(1, 2, 0)  # [H, W, C]\n",
        "                        .mul(255)\n",
        "                        .byte()\n",
        "                        .cpu()\n",
        "                        .numpy()\n",
        "                    )\n",
        "                    img_cropped_pil = Image.fromarray(img_cropped_np)\n",
        "                    face_images.append(img_cropped_pil)\n",
        "\n",
        "                    img_cropped = img_cropped.unsqueeze(0).to(device)\n",
        "                    embedding = resnet(img_cropped).detach().cpu()\n",
        "                    embeddings.append(embedding)\n",
        "                else:\n",
        "                    print(f\"Unexpected tensor shape: {img_cropped.shape}\")\n",
        "    else:\n",
        "        print(f\"No faces detected or low probability for image: {image_path}\")\n",
        "\n",
        "    return embeddings, face_images\n"
      ],
      "metadata": {
        "id": "4NWyP0pnHxe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loading_existing_embedding(face_folder):\n",
        "    print(\"Loading existing embeddings...\")\n",
        "    existing_embeddings = {}\n",
        "    for filename in os.listdir(face_folder):\n",
        "        if filename.endswith('.pt'):\n",
        "            embedding_path = os.path.join(face_folder, filename)\n",
        "            embedding = torch.load(embedding_path)\n",
        "            key = os.path.splitext(filename)[0]\n",
        "            existing_embeddings[key] = embedding\n",
        "    return existing_embeddings\n",
        "\n",
        "\n",
        "def is_new_face(face_folder,new_embedding, threshold=0.6):\n",
        "\n",
        "    existing_embeddings=loading_existing_embedding(face_folder)\n",
        "    for key, existing_embedding in existing_embeddings.items():\n",
        "        distance = torch.norm(new_embedding - existing_embedding).item()\n",
        "        # print(f'Comparing distance with {key}: {distance:.4f}')\n",
        "        if distance < threshold:\n",
        "            print(f'Distance with {key}: {distance:.4f}')\n",
        "            return False, key  # Return False and the most similar key immediately\n",
        "\n",
        "    return True, len(existing_embeddings)  # Return True and the current count if new\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P4AJIpY743t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_embeddings(file_list_path,face_folder):\n",
        "\n",
        "    with open(file_list_path, 'r') as f:\n",
        "        done_scan = []\n",
        "        if os.path.exists(\"done_scan\"):\n",
        "            with open(\"done_scan\", 'r') as f1:\n",
        "                done_scan = [line.strip() for line in f1.readlines()]\n",
        "        filenames = [line.strip() for line in f.readlines()]\n",
        "        if not done_scan:\n",
        "            filenames = filenames\n",
        "        else:\n",
        "            filenames = [filename for filename in filenames if filename not in done_scan]\n",
        "\n",
        "    for image_path in filenames:\n",
        "        if os.path.exists(image_path):\n",
        "            pass\n",
        "        else:\n",
        "            print(f\"File not found: {image_path}\")\n",
        "            continue\n",
        "            print(f\"File not found: {image_path}\")\n",
        "        print(f\"Processing: {image_path}\")\n",
        "        embeddings,faces = get_embedding(image_path)\n",
        "        if embeddings is not []:\n",
        "            for face_and_embedding in zip(embeddings,faces):\n",
        "                print(\"hello\")\n",
        "\n",
        "                face_embedding=face_and_embedding[0]\n",
        "                img_cropped_pil=face_and_embedding[1]\n",
        "\n",
        "                condition , lenth_existing_embedding_or_key_of_existing_fave = is_new_face(face_folder,face_embedding)\n",
        "                if condition:\n",
        "                    print(\"New face detected, saving...\")\n",
        "\n",
        "                    # Save the cropped face image\n",
        "                    face_path = os.path.join(face_folder, f'face_{lenth_existing_embedding_or_key_of_existing_fave + 1}.jpg')\n",
        "                    img_cropped_pil.save(face_path)\n",
        "                    print(f'New face detected and saved as: {face_path}')\n",
        "\n",
        "                    # Save the embedding\n",
        "                    embedding_path = os.path.join(face_folder, f'face_{lenth_existing_embedding_or_key_of_existing_fave + 1}.pt')\n",
        "                    torch.save(face_embedding, embedding_path)\n",
        "                    print(f'Embedding saved as: {embedding_path}')\n",
        "\n",
        "                    # Create a new file to track occurrences of this face\n",
        "                    tracking_file = os.path.join(face_folder, f'face_{lenth_existing_embedding_or_key_of_existing_fave + 1}.txt')\n",
        "                    with open(tracking_file, 'w') as f:\n",
        "                        f.write(image_path + '\\n')  # Add the current image path\n",
        "                    print(f'Tracking file created for face: {tracking_file}')\n",
        "\n",
        "                else:\n",
        "                    # Append the current image path to the file of the most similar face\n",
        "                    tracking_file = os.path.join(face_folder, f'{lenth_existing_embedding_or_key_of_existing_fave}.txt')\n",
        "                    with open(tracking_file, 'a') as f:\n",
        "                        f.write(image_path + '\\n')\n",
        "                    print(f'Appended image path to tracking file: {tracking_file}')\n",
        "\n",
        "                # You can add any logic here for further processing\n",
        "        with open(\"done_scan\", 'a') as f:\n",
        "            f.write(image_path + '\\n')\n",
        "\n"
      ],
      "metadata": {
        "id": "AdAOMU7G8RKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_folder = './faces'\n",
        "os.makedirs(face_folder, exist_ok=True)\n",
        "folder_path = '/content/sample_data/photos'\n",
        "output_file = 'folder1file.txt'\n",
        "save_filenames_to_txt(folder_path, output_file)\n",
        "\n",
        "file_list_path = output_file\n",
        "process_embeddings(file_list_path,face_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zVF9U_Wh43ri",
        "outputId": "d01facb5-d15b-490e-e8b9-4f919afcaa72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All filenames saved to folder1file.txt\n",
            "Processing: /content/sample_data/photos/luc-van-loon-aiaNuzedKkE-unsplash.jpg\n",
            "hello\n",
            "Loading existing embeddings...\n",
            "Distance with face_1: 0.0000\n",
            "Appended image path to tracking file: ./faces/face_1.txt\n",
            "Processing: /content/sample_data/photos/audrey-m-jackson-cAFpd2vqnPE-unsplash.jpg\n",
            "hello\n",
            "Loading existing embeddings...\n",
            "Distance with face_2: 0.0000\n",
            "Appended image path to tracking file: ./faces/face_2.txt\n",
            "Processing: /content/sample_data/photos/omid-armin-yZwrmzKGKZA-unsplash.jpg\n",
            "hello\n",
            "Loading existing embeddings...\n",
            "Distance with face_3: 0.0000\n",
            "Appended image path to tracking file: ./faces/face_3.txt\n",
            "Processing: /content/sample_data/photos/alexis-chloe-TYDkKEgc0Fg-unsplash.jpg\n",
            "hello\n",
            "Loading existing embeddings...\n",
            "Distance with face_4: 0.0000\n",
            "Appended image path to tracking file: ./faces/face_4.txt\n",
            "Processing: /content/sample_data/photos/zulmaury-saavedra-Z9GKfYmWOAM-unsplash.jpg\n",
            "hello\n",
            "Loading existing embeddings...\n",
            "Distance with face_5: 0.0000\n",
            "Appended image path to tracking file: ./faces/face_5.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U2O_luoH43o-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_x8AxFrjIYxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RVeOO0sPIYuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u3nXafjEIhO4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}